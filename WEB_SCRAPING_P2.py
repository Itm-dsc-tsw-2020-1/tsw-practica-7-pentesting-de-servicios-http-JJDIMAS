import sys
import requests as req
from bs4 import BeautifulSoup
import mysql.connector as mysql


def WebScraping(host):
    try:
        #Se requiere colocar http:// antes de la dirección ip
        resp = req.get('http://'+ str(host))        
        #Checar el código de estado, si es 200, hay una página que podemos extraer
        if str(resp.status_code) == "200":
            print("Conexion exitosa con: "+ host)
            s = BeautifulSoup(resp.text, 'html.parser')
            print("Etiquetas FORM encontradas: ")
            print(s.form)
            #Buscamos los href
            print("Enlaces encontrados: ")
            arr = s.find_all('a')
            i = 0
            for a in arr:
                print(a['href'])
                operacion.execute("INSERT INTO enlaces (direccion) VALUES ('"+a['href']+"')")
                conexion.commit()
                i=+1
        else:
            print("Fallo la conexion con: "+ host)

    except:
        print("Unexpected error:", sys.exc_info()[0])
        

def Enlaces(host):
    try:
        #Verificamos si es necesario o no agregar "http"
        if "http://" in host or "https://" in host :
            resp = req.get(str(host))
        else:
            resp = req.get('http://'+ str(host))                    
        #Checar el código de estado, si es 200, hay una página que podemos extraer
        if str(resp.status_code) == "200":
            print("Conexion exitosa con: "+ host)
            s = BeautifulSoup(resp.text, 'html.parser')
            print("Etiquetas FORM encontradas: ")
            print(s.form)
        else:
            print("Fallo la conexion con: "+ host)    

    except:
        print("Unexpected error:", sys.exc_info()[0])
        

#Datos para las operaciones
conexion = mysql.connect( host='localhost', user= 'root', passwd='', db='puertos' )
operacion = conexion.cursor(buffered=True)
operacion.execute( "SELECT distinct ip FROM dato WHERE servicio = 'http' ; " )
for ip in operacion.fetchall() :
    WebScraping(ip[0]) 
#Ahora buscamos las etiquetas form en los enlaces recopilados
#####  NOTA: se limita la busqueda de enlaces a las ip registradas en la base de datos con la finalidad
#####        de que el tiempo de ejecución no se torne sumamente extenso.
operacion.execute( "SELECT direccion FROM enlaces;")
for direccion in operacion.fetchall() :
    Enlaces(direccion[0]) 
conexion.close()